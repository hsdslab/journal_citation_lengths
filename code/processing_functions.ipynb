{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNkRnVFfOobnqmqOlFR5oC0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["a file with functions to do all of the processing steps I always do"],"metadata":{"id":"lLak4PniN_NB"}},{"cell_type":"code","source":["# test function\n","def add_a_b(a,b):\n","    return a+b"],"metadata":{"id":"TiYXW-gFtbke"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BjDBVs2mN7eH"},"outputs":[],"source":["# a function for transforming positive skew data to normal distribution, this is done before t-tests. https://machinelearningmastery.com/skewness-be-gone-transformative-tricks-for-data-scientists/\n","\n","def transform_to_normal(df,name_of_data_column_to_transform,n_quantiles=500): # distances df, column name with distance measure\n","\n","    from scipy import stats\n","    from sklearn.preprocessing import QuantileTransformer\n","\n","    name = name_of_data_column_to_transform\n","\n","    # quantile transformation --\n","    # note it reduces the influence of outliers, which may not be good. also check about recommended values for the n_quantiles parameter\n","    qt = QuantileTransformer(output_distribution='normal',n_quantiles=500, random_state=0)\n","    X = [[val] for val in df[name]]\n","    new_name = str('qt_'+name)\n","    df[new_name] = qt.fit_transform(X)\n","    min_val = abs(min(df[new_name]))\n","    df[new_name] = df[new_name] + min_val # transpose so that there are no negative values\n","\n","    return df"]},{"cell_type":"code","source":["# a function for min-max normalizing the data, this is done before t-tests\n","\n","def min_max_normalize(df,name_of_data_column_to_normalize): # distances df, column name with distance measure\n","\n","  import pandas as pd\n","  import numpy as np\n","  from tqdm import tqdm\n","\n","  name = name_of_data_column_to_normalize\n","  distances = df\n","\n","  # read in discipline information\n","  publisher = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/citation_stacking/data/df_publisher.csv')\n","\n","  # no na vals and all vals are <= 0\n","  print(str(sum(distances[name].isna()))+' nan values in your data column were dropped') # = 1902... a lot\n","  distances.dropna(axis=0,subset=name,inplace=True)\n","\n","  # merge discipline info onto distances df\n","  check1 = len(distances)\n","  distances['id'] = distances['id'].astype(int)\n","  distances = distances.merge(publisher[['journal_id','main_concept']],left_on='id',right_on='journal_id',how='inner')\n","  check2 = len(distances)\n","  if check1 != check2:\n","    print('error: the length of your df changed')\n","\n","  # also check for na discipline values and drop these\n","  print(str(sum(distances['main_concept'].isna()))+' nan discipline values were dropped') # 0\n","  distances.dropna(axis=0,subset='main_concept',inplace=True)\n","\n","  # normalize by discipline\n","  distances.index = distances.journal_id\n","  distances['normalized_dst'] = np.nan\n","  for subj in tqdm(distances['main_concept'].unique()):\n","    temp = distances[distances['main_concept']==subj]\n","    max_num = temp[name].max()\n","    min_num = temp[name].min()\n","    for j in temp['journal_id']:\n","      val = temp.at[j,name]\n","      if val > 0:\n","        normalized = (val - min_num) / (max_num - min_num)\n","      else: # journal has dst = 0\n","        normalized = 0\n","      # save normalized val into df\n","      distances.at[j,'normalized_dst'] = normalized\n","\n","  distances.reset_index(inplace=True,drop=True)\n","\n","  print('your normalized data is stored in the normalized_dst column')\n","\n","  return distances"],"metadata":{"id":"aEWRGbQvwKCA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function for comparing distance distributions by njr ranking\n","\n","def compare_njr(distances,dst_name):\n","\n","  import matplotlib.pyplot as plt\n","  import pandas as pd\n","  import numpy as np\n","\n","  # norwegian journal ranking: https://kanalregister.hkdir.no/publiseringskanaler/Om\n","  njr = pd.read_excel('/content/drive/MyDrive/CitationsProject/validation_data/Validation_data_with_openalex/openalex_NorwegianJournalRank.xlsx')\n","  njr['Level 2022'].value_counts()\n","\n","  njr = njr[['Level 2022','journal_openalex_id']]\n","  distances_merge = distances[['normalized_dst','journal_id']]\n","  ttest_df = njr.merge(distances_merge,left_on='journal_openalex_id',right_on='journal_id')\n","  len(ttest_df)\n","\n","  # level 2 journals are top level 0 should be rejected\n","  data1 = ttest_df[ttest_df['Level 2022']==2]['normalized_dst'].to_numpy()\n","  data2 = ttest_df[ttest_df['Level 2022']==1]['normalized_dst'].sample(n=len(data1),random_state=1).to_numpy()\n","  data3 = ttest_df[ttest_df['Level 2022']==0]['normalized_dst'].to_numpy()\n","\n","  # or instead we could just compare top journnals to the rest\n","  #data2 = ttest_df[(ttest_df['Level 2022']==0) | (ttest_df['Level 2022']==1)].sample(n=len(data1),random_state=1)['qt_citing_cited'].to_numpy()\n","\n","  plt.hist(data1,bins=100,color=[1,0,0,0.5])\n","  plt.hist(data2,bins=100,color=[0,0,1,0.5])\n","  plt.hist(data3,bins=100,color=[0,1,0,0.5])\n","  plt.legend(['level 2, mean='+str(round(np.mean(data1),2)), 'level 1, mean='+str(round(np.mean(data2),2)), 'level 0, mean='+str(round(np.mean(data3),2))])\n","\n","  plt.title('Distributions of '+dst_name+' Distance by NJR Rank Categories')\n","  plt.ylabel('number of journals')\n","  plt.xlabel('mean '+dst_name+' incoming citation length')\n","  plt.savefig('njr_dst_distributions.png')\n","\n","  plt.show()\n","\n","  # display table with t-tests\n","  from scipy.stats import ttest_ind\n","\n","  # function for coloring cells differently for significant results\n","  def _color_red_or_green(val):\n","    color = 'red' if val > 0.05 else 'green'\n","    return 'color: %s' % color\n","\n","  display_df = pd.DataFrame({'Level 2': ['X','X','X'],'Level 1': ['X','X','X'],'Level 0':['X','X','X']},index=['Level 2','Level 1','Level 0'])\n","\n","  for i in range(0,3):\n","\n","    print('Level '+str(i)+', n = '+str(len(ttest_df[ttest_df['Level 2022']==i])))\n","\n","    for j in range(0,3):\n","\n","      data1 = ttest_df[ttest_df['Level 2022']==i]['normalized_dst'].dropna(axis=0)\n","      data2 = ttest_df[ttest_df['Level 2022']==j]['normalized_dst'].dropna(axis=0)\n","      stat, p = ttest_ind(data1, data2)\n","\n","      display_df.at[str('Level '+str(i)),str('Level '+str(j))] = p #str('p = ' + str(round(p,4)) + ',  n = ' + str(len(data1)+len(data2)))\n","\n","  print('p values:')\n","\n","  return display_df.style.applymap(_color_red_or_green)"],"metadata":{"id":"BpbI8UoHTZja"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function for comparing distance distributions by jufo ranking\n","\n","def compare_jufo(distances,dst_name):\n","\n","  import matplotlib.pyplot as plt\n","  import pandas as pd\n","  import numpy as np\n","\n","  # finish journal ranking:\n","  jufo = pd.read_excel('/content/drive/MyDrive/CitationsProject/validation_data/Validation_data_with_openalex/JUFO_Journal_Rank.xlsx')\n","  jufo['TASO/LEVEL/NIVÅ'].value_counts()\n","\n","  jufo = jufo[['TASO/LEVEL/NIVÅ','journal_openalex_id']]\n","  distances_merge = distances[['normalized_dst','journal_id']]\n","  ttest_df = jufo.merge(distances_merge,left_on='journal_openalex_id',right_on='journal_id')\n","  len(ttest_df)\n","\n","  # level 2 journals are top level 0 should be rejected\n","  data2 = ttest_df[ttest_df['TASO/LEVEL/NIVÅ']==2]['normalized_dst'].to_numpy()\n","  data1 = ttest_df[ttest_df['TASO/LEVEL/NIVÅ']==1]['normalized_dst'].sample(n=len(data2),random_state=1).to_numpy()\n","  data0 = ttest_df[ttest_df['TASO/LEVEL/NIVÅ']==0]['normalized_dst'].to_numpy()\n","  data3 = ttest_df[ttest_df['TASO/LEVEL/NIVÅ']==3]['normalized_dst'].to_numpy()\n","\n","  # or instead we could just compare top journnals to the rest\n","  #data2 = ttest_df[(ttest_df['Level 2022']==0) | (ttest_df['Level 2022']==1)].sample(n=len(data1),random_state=1)['qt_citing_cited'].to_numpy()\n","\n","  plt.hist(data3,bins=100,color=[0,0,0,0.5])\n","  plt.hist(data2,bins=100,color=[1,0,0,0.5])\n","  plt.hist(data1,bins=100,color=[0,0,1,0.5])\n","  plt.hist(data0,bins=100,color=[0,1,0,0.5])\n","  plt.legend(['level 3, mean='+str(round(np.mean(data3),2)), 'level 2, mean='+str(round(np.mean(data2),2)), 'level 1, mean='+str(round(np.mean(data1),2)), 'level 0, mean='+str(round(np.mean(data0),2))])\n","\n","  plt.title('Distributions of '+dst_name+' Distance by JUFO Rank Categories')\n","  plt.ylabel('number of journals')\n","  plt.xlabel('mean '+dst_name+' incoming citation length')\n","  plt.savefig('jufo_dst_distributions.png')\n","\n","  plt.show()\n","\n","  # display table with t-tests\n","  from scipy.stats import ttest_ind\n","\n","  # function for coloring cells differently for significant results\n","  def _color_red_or_green(val):\n","    color = 'red' if val > 0.05 else 'green'\n","    return 'color: %s' % color\n","\n","  display_df = pd.DataFrame({'Level 3': ['X','X','X','X'],'Level 2': ['X','X','X','X'],'Level 1':['X','X','X','X'],'Level 0':['X','X','X','X']},index=['Level 3','Level 2','Level 1','Level 0'])\n","\n","  for i in range(0,4):\n","\n","    print('Level '+str(i)+', n = '+str(len(ttest_df[ttest_df['TASO/LEVEL/NIVÅ']==i])))\n","\n","    for j in range(0,4):\n","\n","      data1 = ttest_df[ttest_df['TASO/LEVEL/NIVÅ']==i]['normalized_dst'].dropna(axis=0)\n","      data2 = ttest_df[ttest_df['TASO/LEVEL/NIVÅ']==j]['normalized_dst'].dropna(axis=0)\n","      stat, p = ttest_ind(data1, data2)\n","\n","      display_df.at[str('Level '+str(i)),str('Level '+str(j))] = p #str('p = ' + str(round(p,4)) + ',  n = ' + str(len(data1)+len(data2)))\n","\n","  print('p values:')\n","\n","  return display_df.style.applymap(_color_red_or_green)"],"metadata":{"id":"bPVEt1rMgZLF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function for comparing distance distributions by scimago ranking\n","\n","def compare_scimago(distances,dst_name):\n","\n","  import matplotlib.pyplot as plt\n","  import pandas as pd\n","  import numpy as np\n","\n","  # scimago journal ranking:\n","  scimago = pd.read_excel('/content/drive/MyDrive/CitationsProject/validation_data/Validation_data_with_openalex/openalex_scimagojr_2022_RAW.xlsx')\n","  scimago.drop_duplicates(subset = 'journal_openalex_id', inplace=True) # this has to be redone so as not to use this line\n","  len(scimago)\n","  scimago['SJR Best Quartile'].value_counts()\n","\n","  scimago = scimago[['SJR Best Quartile','journal_openalex_id']]\n","  distances_merge = distances[['normalized_dst','journal_id']]\n","  ttest_df = scimago.merge(distances_merge,left_on='journal_openalex_id',right_on='journal_id')\n","  len(ttest_df)\n","\n","  # level 2 journals are top level 0 should be rejected\n","  data3 = ttest_df[ttest_df['SJR Best Quartile']=='Q3']['normalized_dst'].to_numpy()\n","  data1 = ttest_df[ttest_df['SJR Best Quartile']=='Q1']['normalized_dst'].sample(n=len(data3),random_state=1).to_numpy()\n","  data2 = ttest_df[ttest_df['SJR Best Quartile']=='Q2']['normalized_dst'].sample(n=len(data3),random_state=1).to_numpy()\n","  data4 = ttest_df[ttest_df['SJR Best Quartile']=='Q4']['normalized_dst'].to_numpy()\n","\n","  # or instead we could just compare top journnals to the rest\n","  #data2 = ttest_df[(ttest_df['Level 2022']==0) | (ttest_df['Level 2022']==1)].sample(n=len(data1),random_state=1)['qt_citing_cited'].to_numpy()\n","\n","  plt.hist(data1,bins=100,color=[1,0,0,0.5])\n","  plt.hist(data2,bins=100,color=[0,0,1,0.5])\n","  plt.hist(data3,bins=100,color=[0,1,0,0.5])\n","  plt.hist(data4,bins=100,color=[0,0,0,0.5])\n","  plt.legend(['Q1, mean='+str(round(np.mean(data1),2)), 'Q2, mean='+str(round(np.mean(data2),2)), 'Q3, mean='+str(round(np.mean(data3),2)), 'Q4, mean='+str(round(np.mean(data4),2))])\n","\n","  plt.title('Distributions of '+dst_name+' Distance by SJR Quartiles')\n","  plt.ylabel('number of journals')\n","  plt.xlabel('mean '+dst_name+' incoming citation length')\n","  plt.savefig('sjr_dst_distributions.png')\n","\n","  plt.show()\n","\n","  # display table with t-tests\n","  from scipy.stats import ttest_ind\n","\n","  # function for coloring cells differently for significant results\n","  def _color_red_or_green(val):\n","    color = 'red' if val > 0.05 else 'green'\n","    return 'color: %s' % color\n","\n","  display_df = pd.DataFrame({'Q1': ['X','X','X','X'],'Q2': ['X','X','X','X'],'Q3':['X','X','X','X'],'Q4':['X','X','X','X']},index=['Q1','Q2','Q3','Q4'])\n","\n","  for i in ['Q1','Q2','Q3','Q4']:\n","\n","    print(i+', n = '+str(len(ttest_df[ttest_df['SJR Best Quartile']==i])))\n","\n","    for j in ['Q1','Q2','Q3','Q4']:\n","\n","      data1 = ttest_df[ttest_df['SJR Best Quartile']==i]['normalized_dst'].dropna(axis=0)\n","      data2 = ttest_df[ttest_df['SJR Best Quartile']==j]['normalized_dst'].dropna(axis=0)\n","      stat, p = ttest_ind(data1, data2)\n","\n","      display_df.at[i,j] = p #str('p = ' + str(round(p,4)) + ',  n = ' + str(len(data1)+len(data2)))\n","\n","  print('p values:')\n","\n","  return display_df.style.applymap(_color_red_or_green)"],"metadata":{"id":"n4Z43XeAqqm6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function for comparing distance distributions by jcr_suppressed journals\n","\n","def compare_jcr_suppressed(distances,dst_name):\n","\n","  import matplotlib.pyplot as plt\n","  import pandas as pd\n","  import numpy as np\n","\n","  # jcr_suppressed journal ranking:\n","  jcr_suppressed = pd.read_json('/content/drive/MyDrive/CitationsProject/validation_data/Validation_data_with_openalex/JCR_suppressed_journal_openalex.json')\n","  jcr_suppressed['suppressed'] = 1\n","  jcr_suppressed.head()\n","\n","  jcr_suppressed = jcr_suppressed[['suppressed','journal_id']]\n","  distances_merge = distances[['normalized_dst','journal_id']]\n","  ttest_df = jcr_suppressed.merge(distances_merge,on='journal_id',how='right',indicator=True)\n","  print(len(ttest_df))\n","  ttest_df['_merge'].value_counts()\n","\n","  # rejected journals are merged with 'both' indicator while normal come from the 'right_only' df\n","  data1 = ttest_df[ttest_df['_merge']=='both']['normalized_dst'].to_numpy()\n","  data0 = ttest_df[ttest_df['_merge']=='right_only']['normalized_dst'].sample(n=len(data1),random_state=1).to_numpy()\n","\n","  plt.hist(data1,bins=50,color=[1,0,0,0.5])\n","  plt.hist(data0,bins=50,color=[0,0,1,0.5])\n","  plt.legend(['suppressed, mean='+str(round(np.mean(data1),2)), 'normal, mean='+str(round(np.mean(data0),2))])\n","\n","  plt.title('Distributions of '+dst_name+' for JCR-Suppressed and normal journals')\n","  plt.ylabel('number of journals')\n","  plt.xlabel('mean '+dst_name+' incoming citation length')\n","  plt.savefig('jcr_suppressed_dst_distributions.png')\n","  plt.show()\n","\n","  # display table with t-tests\n","  from scipy.stats import ttest_ind\n","\n","  # function for coloring cells differently for significant results\n","  def _color_red_or_green(val):\n","    color = 'red' if val > 0.05 else 'green'\n","    return 'color: %s' % color\n","\n","  display_df = pd.DataFrame({'both': ['X','X'],'right_only': ['X','X']},index=['both','right_only'])\n","\n","  for i in ['both','right_only']:\n","\n","    # print n, number of items in t-test comparison groups\n","    if i=='both':\n","      name='suppressed'\n","    else:\n","      name='normal'\n","    print(name+', n = '+str(len(ttest_df[ttest_df['_merge']==i])))\n","\n","    for j in ['both','right_only']:\n","\n","      data1 = ttest_df[ttest_df['_merge']==i]['normalized_dst'].dropna(axis=0)\n","      data2 = ttest_df[ttest_df['_merge']==j]['normalized_dst'].dropna(axis=0)\n","      stat, p = ttest_ind(data1, data2)\n","\n","      display_df.at[i,j] = p #str('p = ' + str(round(p,4)) + ',  n = ' + str(len(data1)+len(data2)))\n","\n","  print('p values:')\n","\n","  display_df.rename({'both':'suppressed','right_only':'normal'},inplace=True,axis=1)\n","  display_df.index = ['suppressed','normal']\n","\n","  return display_df.style.applymap(_color_red_or_green)"],"metadata":{"id":"IgxUyGsugQlY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function for comparing distance distributions by jcr_suppressed journals\n","\n","def compare_jcr_suppressed_supplemental(distances,dst_name):\n","\n","  import matplotlib.pyplot as plt\n","  import pandas as pd\n","  import numpy as np\n","\n","  # jcr_suppressed journal ranking:\n","  jcr_suppressed = pd.read_json('/content/drive/MyDrive/CitationsProject/validation_data/Validation_data_with_openalex/JCR_suppressed_journal_openalex.json')\n","  jcr_suppressed['suppressed'] = 1\n","  jcr_suppressed.head()\n","\n","  jcr_suppressed = jcr_suppressed[['suppressed','journal_id']]\n","\n","  # ADD in our calculated JCR suppressed too\n","  import pickle\n","  with open('/content/drive/MyDrive/CitationsProject/validation_data/Validation_data_with_openalex/JCR_suppressed_supplemental.pkl', 'rb') as f:\n","      jcr_suplemental = pickle.load(f)\n","\n","  # check how many of the ones from the actual list we found\n","  len(jcr_suppressed[jcr_suppressed['journal_id'].isin(jcr_suplemental)]) # not good requires work\n","  all_jcr = list(jcr_suppressed['journal_id']) + jcr_suplemental\n","  len(all_jcr)\n","  # remove duplicates\n","  all_jcr = set(all_jcr)\n","  print(len(all_jcr))\n","\n","  # make into df and then it's the same process as previously\n","  all_jcr = pd.DataFrame({'journal_id':list(all_jcr)})\n","  all_jcr['suppressed'] = 1\n","\n","  jcr_suppressed = pd.concat([jcr_suppressed,all_jcr])\n","\n","  # DONE adding\n","\n","  distances_merge = distances[['normalized_dst','journal_id']]\n","  ttest_df = jcr_suppressed.merge(distances_merge,on='journal_id',how='right',indicator=True)\n","  print(len(ttest_df))\n","  ttest_df['_merge'].value_counts()\n","\n","  # rejected journals are merged with 'both' indicator while normal come from the 'right_only' df\n","  data1 = ttest_df[ttest_df['_merge']=='both']['normalized_dst'].to_numpy()\n","  data0 = ttest_df[ttest_df['_merge']=='right_only']['normalized_dst'].sample(n=len(data1),random_state=1).to_numpy()\n","\n","  plt.hist(data1,bins=50,color=[1,0,0,0.5])\n","  plt.hist(data0,bins=50,color=[0,0,1,0.5])\n","  plt.legend(['suppressed, mean='+str(round(np.mean(data1),2)), 'normal, mean='+str(round(np.mean(data0),2))])\n","\n","  plt.title('Distributions of '+dst_name+' for JCR-Suppressed and normal journals')\n","  plt.ylabel('number of journals')\n","  plt.xlabel('mean '+dst_name+' incoming citation length')\n","  plt.savefig('jcr_suppressed_dst_distributions.png')\n","  plt.show()\n","\n","  # display table with t-tests\n","  from scipy.stats import ttest_ind\n","\n","  # function for coloring cells differently for significant results\n","  def _color_red_or_green(val):\n","    color = 'red' if val > 0.05 else 'green'\n","    return 'color: %s' % color\n","\n","  display_df = pd.DataFrame({'both': ['X','X'],'right_only': ['X','X']},index=['both','right_only'])\n","\n","  for i in ['both','right_only']:\n","\n","    # print n, number of items in t-test comparison groups\n","    if i=='both':\n","      name='suppressed'\n","    else:\n","      name='normal'\n","    print(name+', n = '+str(len(ttest_df[ttest_df['_merge']==i])))\n","\n","    for j in ['both','right_only']:\n","\n","      data1 = ttest_df[ttest_df['_merge']==i]['normalized_dst'].dropna(axis=0)\n","      data2 = ttest_df[ttest_df['_merge']==j]['normalized_dst'].dropna(axis=0)\n","      stat, p = ttest_ind(data1, data2)\n","\n","      display_df.at[i,j] = p #str('p = ' + str(round(p,4)) + ',  n = ' + str(len(data1)+len(data2)))\n","\n","  print('p values:')\n","\n","  display_df.rename({'both':'suppressed','right_only':'normal'},inplace=True,axis=1)\n","  display_df.index = ['suppressed','normal']\n","\n","  return display_df.style.applymap(_color_red_or_green)"],"metadata":{"id":"6_cBSkFIeaLf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function for comparing distance distributions by cidre anomalous\n","\n","def compare_cidre(distances,dst_name):\n","\n","  import matplotlib.pyplot as plt\n","  import pandas as pd\n","  import numpy as np\n","\n","  # jcr_suppressed journal ranking:\n","  cidre = pd.read_json('/content/drive/MyDrive/CitationsProject/validation_data/Validation_data_with_openalex/cidre_anomalous_009.json') # 1275\n","  cidre.head()\n","\n","  cidre = cidre[['anomalous','journal_id']]\n","  distances_merge = distances[['normalized_dst','journal_id']]\n","  ttest_df = cidre.merge(distances_merge,on='journal_id',how='right',indicator=True)\n","  print(len(ttest_df))\n","  ttest_df['_merge'].value_counts()\n","\n","  # rejected journals are merged with 'both' indicator while normal come from the 'right_only' df\n","  data1 = ttest_df[ttest_df['anomalous']==1]['normalized_dst'].to_numpy()\n","  data0 = ttest_df[ttest_df['anomalous']==0]['normalized_dst'].sample(n=len(data1),random_state=1).to_numpy()\n","\n","  plt.hist(data1,bins=50,color=[1,0,0,0.5])\n","  plt.hist(data0,bins=50,color=[0,0,1,0.5])\n","  plt.legend(['anomalous, mean='+str(round(np.mean(data1),2)), 'normal, mean='+str(round(np.mean(data0),2))])\n","\n","  plt.title('Distributions of '+dst_name+' for CIDRE-identified anomalous journals')\n","  plt.ylabel('number of journals')\n","  plt.xlabel('mean '+dst_name+' incoming citation length')\n","  plt.savefig('cidre_anomalous_dst_distributions.png')\n","  plt.show()\n","\n","  # display table with t-tests\n","  from scipy.stats import ttest_ind\n","\n","  # function for coloring cells differently for significant results\n","  def _color_red_or_green(val):\n","    color = 'red' if val > 0.05 else 'green'\n","    return 'color: %s' % color\n","\n","  display_df = pd.DataFrame({1: ['X','X'],0: ['X','X']},index=[1,0])\n","\n","  for i in [0,1]:\n","\n","    if i == 0:\n","      name = 'normal'\n","    else:\n","      name = 'anomalous'\n","    print(name+', n = '+str(len(ttest_df[ttest_df['anomalous']==i])))\n","\n","    for j in [0,1]:\n","\n","      data1 = ttest_df[ttest_df['anomalous']==i]['normalized_dst'].dropna(axis=0)\n","      data2 = ttest_df[ttest_df['anomalous']==j]['normalized_dst'].dropna(axis=0)\n","      stat, p = ttest_ind(data1, data2)\n","\n","      display_df.at[i,j] = p #str('p = ' + str(round(p,4)) + ',  n = ' + str(len(data1)+len(data2)))\n","\n","  print('p values:')\n","\n","  display_df.rename({1:'anomalous',0:'normal'},inplace=True,axis=1)\n","  display_df.index = ['anomalous','normal']\n","\n","  return display_df.style.applymap(_color_red_or_green)"],"metadata":{"id":"32KMqswNSl3S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# jif comparison function\n","\n","def jif_comparison(distances):\n","\n","  from sklearn import metrics\n","  import pandas as pd\n","  import matplotlib.pyplot as plt\n","  import numpy as np\n","\n","  # load jif data\n","  print('loading jif data')\n","  jif = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/citation_stacking/data/validation_data/our_calculated_jif.csv')\n","  jif.drop('Unnamed: 0',axis=1,inplace=True)\n","\n","  # load validation data\n","  print('loading njr data')\n","  njr = pd.read_excel('/content/drive/MyDrive/CitationsProject/validation_data/Validation_data_with_openalex/openalex_NorwegianJournalRank.xlsx')\n","  njr = njr[['Level 2022','journal_openalex_id']]\n","\n","  print('loading jufo data')\n","  jufo = pd.read_excel('/content/drive/MyDrive/CitationsProject/validation_data/Validation_data_with_openalex/JUFO_Journal_Rank.xlsx')\n","  jufo = jufo[['TASO/LEVEL/NIVÅ','journal_openalex_id']]\n","\n","  print('loading scimago data')\n","  scimago = pd.read_excel('/content/drive/MyDrive/CitationsProject/validation_data/Validation_data_with_openalex/openalex_scimagojr_2022_RAW.xlsx')\n","  scimago.drop_duplicates(subset = 'journal_openalex_id', inplace=True)\n","  scimago = scimago[['SJR Best Quartile','journal_openalex_id']]\n","\n","  # merge validation data with jif and distances data\n","  distances_merge = distances[['weighted_JIF','id']]\n","\n","  roc_df = njr.merge(distances_merge,left_on='journal_openalex_id',right_on='id')\n","  roc_df = jufo.merge(roc_df,left_on='journal_openalex_id',right_on='id')\n","  roc_df = scimago.merge(roc_df,left_on='journal_openalex_id',right_on='id')\n","  roc_df = jif.merge(roc_df, left_on ='journal_id', right_on='id')\n","  roc_df.dropna(inplace=True)\n","\n","  # function for plotting roc curve\n","  def plot_roc_cur(fper, tper, ax, color):\n","    #ax.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n","    ax.plot(fper, tper, color=color, label='ROC')\n","    ax.set_xlabel('False Positive Rate')\n","    ax.set_ylabel('True Positive Rate')\n","    #ax.set_title('Receiver Operating Characteristic (ROC) Curve')\n","\n","  # compare AUC for identifying normal vs excelent journals\n","\n","  for v_name,col_name,upper,lower in [('Scimago','SJR Best Quartile','Q1','Q4'),('JUFO','TASO/LEVEL/NIVÅ',3,0),('NJR','Level 2022',2,0)]:\n","    # simple JIF\n","    samples_from_distrub1 = roc_df[roc_df[col_name]==lower]['jif']\n","    samples_from_distrub2 = roc_df[roc_df[col_name]==upper]['jif']\n","\n","    label = np.concatenate([np.zeros(len(samples_from_distrub1)),np.ones(len(samples_from_distrub2))]).astype(bool)\n","    y_pred = np.concatenate([samples_from_distrub1,samples_from_distrub2])\n","\n","    fpr, tpr, thresholds = metrics.roc_curve(label, y_pred)\n","    chance_to_beat = metrics.auc(fpr, tpr)\n","    #print('JIF: ' + str(round(chance_to_beat,3)))\n","\n","    # weighted jif\n","    samples_from_distrub1 = roc_df[roc_df[col_name]==lower]['weighted_JIF']\n","    samples_from_distrub2 = roc_df[roc_df[col_name]==upper]['weighted_JIF']\n","\n","    label = np.concatenate([np.zeros(len(samples_from_distrub1)),np.ones(len(samples_from_distrub2))]).astype(bool)\n","    y_pred = np.concatenate([samples_from_distrub1,samples_from_distrub2])\n","\n","    fpr_weighted, tpr_weighted, thresholds = metrics.roc_curve(label, y_pred)\n","    chance_to_beat_weighted = metrics.auc(fpr_weighted, tpr_weighted)\n","    #print('weighted JIF: ' + str(round(chance_to_beat_weighted,3)))\n","\n","    fig, ax = plt.subplots()\n","    plot_roc_cur(fpr, tpr, ax, color='red')\n","    plot_roc_cur(fpr_weighted, tpr_weighted, ax, color='green')\n","\n","    plt.title('ROC - '+v_name+' validation set')\n","    plt.tight_layout()\n","    plt.legend(['JIF, AUC: '+str(round(chance_to_beat,3)),'weighted, AUC: '+str(round(chance_to_beat_weighted,3))])\n","    plt.savefig(v_name+'_roc_comparisons.png')\n","    plt.show()\n"],"metadata":{"id":"QZMa2oSmNiS0"},"execution_count":null,"outputs":[]}]}